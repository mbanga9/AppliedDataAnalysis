{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/robin/GIT/ADA2017-Tutorials/02 - Intro to Pandas/Data\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = '/home/robin/GIT/ADA2017-Tutorials/02 - Intro to Pandas/Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "print(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method to concat all the reports files for each country in a single dataframe\n",
    "def concat_files(path,date_str):\n",
    "    the_files = glob.glob(path +\"/*.csv\")\n",
    "    data_frame = pd.DataFrame()\n",
    "    for x in the_files:\n",
    "        df_temp = pd.read_csv(x,parse_dates=[date_str])\n",
    "        data_frame = pd.concat([data_frame,df_temp])\n",
    "    return data_frame\n",
    "\n",
    "# Method to add a Month column\n",
    "def add_month(df):\n",
    "    copy_df = df.copy()\n",
    "    months = [calendar.month_name[x.month] for x in copy_df.Date]\n",
    "    copy_df['Month'] = months\n",
    "    return copy_df\n",
    "\n",
    "# Method to calculate the average number of new cases per month\n",
    "def calculate_avg_new_cases(df, totals_id='New Cases'):\n",
    "    months = df['Month'].unique()\n",
    "    avg_cases = np.zeros(len(months))\n",
    "    for i in range(len(months)):\n",
    "        temp = (df.loc[df['Month'] == months[i]]) # Select relevant month\n",
    "        temp = temp.dropna()\n",
    "        temp = temp[totals_id].values.astype(float) # Extract array of floats\n",
    "        if(len(temp) < 2 ): # If less than two points, assign NaN\n",
    "            avg_cases[i] = np.nan\n",
    "        else: # Otherwise sum/number\n",
    "            avg_cases[i] = temp.sum()/temp.shape[0]\n",
    "        if avg_cases[i] < 0:\n",
    "            raise ValueError('Value of an average is less than 0 during month:', months[i])\n",
    "    return avg_cases  \n",
    "\n",
    "# Method to calculate the average number of deaths per month\n",
    "def calculate_avg_new_deaths(df, totals_id='Total Deaths'):\n",
    "    months = df['Month'].unique()\n",
    "    avg_cases = np.zeros(len(months))\n",
    "    for i in range(len(months)):\n",
    "        temp = (df.loc[df['Month'] == months[i]]) # Selecting relevant month\n",
    "        temp = temp.dropna()\n",
    "        temp = temp.reset_index()  \n",
    "        if(len(temp) > 1):\n",
    "            delta_t = temp['Date'].loc[len(temp)-1] - temp['Date'].loc[0] # calculate time-span of data\n",
    "        temp = temp[totals_id].values.astype(float) # Extracting array of floats   \n",
    "        if(len(temp) < 2): # If less than two points, assign NaN\n",
    "            avg_cases[i] = np.nan\n",
    "        elif(temp[len(temp)-1]-temp[0] > 0):   # if there is a difference between 1st/last time point\n",
    "            avg_cases[i] = (temp[len(temp)-1]-temp[0])/delta_t.days\n",
    "        else: \n",
    "            avg_cases[i] = (temp[len(temp)-2]-temp[0])/delta_t.days\n",
    "        if avg_cases[i] < 0:\n",
    "            raise ValueError('Value of an average is less than 0 during month:',months[i])\n",
    "    return avg_cases   \n",
    "\n",
    "# Method to handle Sierra Leon and Liberia data\n",
    "# Todo: should ideally replace this with Pandas functions, so we get proper NaN handling\n",
    "# and avoid the SettingWithCopyWarning\n",
    "def handle_data(df,desc1,desc2,desc3,new_total):\n",
    "    sl_1 = df[df['Description'] ==desc1]\n",
    "    sl_2 = df[df['Description'] ==desc2]\n",
    "    sl_3 = df[df['Description'] ==desc3]\n",
    "    new_cases_registered =  [int(a) + int(b) + int(c) for a,b,c in zip(sl_1.Totals,sl_2.Totals,sl_3.Totals)]\n",
    "    sl_1[new_total] = new_cases_registered\n",
    "    sl_1 = sl_1[['Date',new_total]]\n",
    "    return sl_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-403fb43fa22c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create Guinea DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mguinea_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/ebola/guinea_data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mg_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguinea_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Shape of Guinea DF:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9df43a1c72d2>\u001b[0m in \u001b[0;36mconcat_files\u001b[0;34m(path, date_str)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcat_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mthe_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"/*.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Guinea DF\n",
    "guinea_folder = DATA_FOLDER + '/ebola/guinea_data/'\n",
    "g_df = concat_files(guinea_folder,'Date')\n",
    "print('Shape of Guinea DF:', g_df.shape)\n",
    "\n",
    "# We can check all unique descriptions in order to choose what \n",
    "# to base our calculations on as well as to be sure not to miss anything.\n",
    "# add print() to display these descriptions\n",
    "g_df['Description'].unique()\n",
    "\n",
    "# We can then see which descriptors appear to be the most complete,\n",
    "# in this case it seems using one of the total deaths descriptors\n",
    "# is the only sensible option, the new deaths data sets are much\n",
    "# less complete. We'll take the confirmed+probables+suspects, so\n",
    "# the end results are probably overestimating the deaths a bit\n",
    "print(g_df.loc[g_df['Description']=='Total deaths of probables'].shape)\n",
    "print(g_df.loc[g_df['Description']=='Total deaths of confirmed'].shape)\n",
    "print(g_df.loc[g_df['Description']=='Total deaths (confirmed + probables + suspects)'].shape)\n",
    "print(g_df.loc[g_df['Description']=='New deaths registered'].shape)\n",
    "print(g_df.loc[g_df['Description']=='New deaths registered today'].shape)\n",
    "print(g_df.loc[g_df['Description']=='New deaths registered today (probables)'].shape)\n",
    "print(g_df.loc[g_df['Description']=='New deaths registered today (suspects)'].shape)\n",
    "g_df.loc[g_df['Description']=='Total deaths (confirmed + probables + suspects)'][['Date','Description','Totals']]\n",
    "\n",
    "# We can already see in this table that the value for\n",
    "# 2014-08-26 seems wrong compared to its neighbours, however\n",
    "# because of how we choose to calculate that average daily\n",
    "# deaths this won't matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally get to calculate average daily new cases and deaths per month.\n",
    "In this data, we assume that the *Total deaths (confirmed + probables + suspects)* row we used from the original data is a cumulative value of the deaths. Therefore we'll calculate the daily average per month of deaths by taking the difference at the beginning and end of a month and divide by the number of days the data points cover.\n",
    "\n",
    "However, the case for the *Total new cases registered so far* column was not as clear. If we look at the output of the next cell, the values for August appear to increasee monotonically as a a cumulative variable would. While the values for September seem to fluctuate more. We therefore chose to interpret this column as *daily* new cases registered, as this is compatible with the fluctuations observed in September. The daily average per month of new cases is therefore calculated as the average of these data points.\n",
    "\n",
    "In both cases we require at least two data points to calculate an average, otherwise we return a `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We only keep the columns of interest\n",
    "g_df = g_df[['Date', 'Description', 'Totals']]\n",
    "\n",
    "# We select the rows that we need in order to calculate our values\n",
    "# We'll create a new df with two columns 'Total Deaths' and 'New Cases'\n",
    "g_new_cases = (g_df.loc[g_df['Description'] == 'Total new cases registered so far'])\n",
    "g_new_cases = g_new_cases.rename(columns={'Totals':'New Cases'})\n",
    "g_new_cases.drop('Description', axis=1, inplace=True)\n",
    "\n",
    "g_total_deaths = (g_df.loc[g_df['Description'] == 'Total deaths (confirmed + probables + suspects)'])\n",
    "g_total_deaths = g_total_deaths.rename(columns={'Totals':'Total Deaths'})\n",
    "g_total_deaths.drop('Description', axis=1, inplace=True)\n",
    "\n",
    "# Create a merged DataFrame with these values\n",
    "g_df = pd.merge(g_total_deaths, g_new_cases, on='Date', how='outer')\n",
    "\n",
    "# Add 'Month' and 'Country' columns to df\n",
    "g_df = add_month(g_df) # Add a 'Month' column, parsed from the 'Date' column\n",
    "g_df['Country'] = 'Guinea' # Add a 'Country' column, for later merging\n",
    "g_df.sort_values('Date', inplace=True)\n",
    "g_df.head(10)\n",
    "\n",
    "# We see that the data from the 2014-08-26 is not consistant but since we only use\n",
    "# the first and last value of each month to calculate the avg we ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Daily average deaths per month:',calculate_avg_new_deaths(g_df))\n",
    "print('Daily average new cases per month:',calculate_avg_new_cases(g_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Sierra Leone DataFrame\n",
    "sl_folder = DATA_FOLDER + '/ebola/sl_data/'\n",
    "sl_df = concat_files(sl_folder,'date')\n",
    "\n",
    "# We only keep the columns of interest \n",
    "sl_df = sl_df[['date','variable','National']]\n",
    "sl_df.columns = ['Date' , 'Description' , 'Totals']\n",
    "sl_df = sl_df.fillna(0)\n",
    "\n",
    "# Creating dataframes for new cases and new deaths\n",
    "sl_new_cases = handle_data(sl_df,'new_confirmed','new_probable','new_suspected','New Cases')\n",
    "sl_new_cases = sl_new_cases.loc[sl_new_cases['New Cases'] > 0] # filtering out 0 cases\n",
    "sl_new_deaths = handle_data(sl_df,'death_confirmed','death_probable','death_suspected','Total Deaths')\n",
    "sl_new_deaths = sl_new_deaths[sl_new_deaths['Total Deaths'] > 0] # filtering out 0 cases\n",
    "\n",
    "# Forming the Sierra Leon DataFrame\n",
    "sl_df = pd.merge(sl_new_cases, sl_new_deaths, on='Date', how='outer')\n",
    "sl_df['Country'] = 'Sierra Leone' \n",
    "sl_df.sort_values('Date', inplace=True)\n",
    "sl_df = add_month(sl_df) # Add a 'Month' column, parsed from the 'Date' column\n",
    "sl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the daily average per month of new cases and deaths for Sierra Leon\n",
    "\n",
    "print('Daily average deaths per month:',calculate_avg_new_deaths(sl_df))\n",
    "print('Daily average new cases per month:',calculate_avg_new_cases(sl_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Liberia DataFrame\n",
    "lib_folder = DATA_FOLDER + '/ebola/liberia_data/'\n",
    "lib_df = concat_files(lib_folder,'Date')\n",
    "\n",
    "# We only keep the columns of interest \n",
    "lib_df = lib_df[['Date','Variable','National']]\n",
    "lib_df.columns = ['Date' , 'Description' , 'Totals']\n",
    "lib_df = lib_df.fillna(0)\n",
    "lib_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating dataframes for new cases and new deaths\n",
    "lib_new_cases = handle_data(lib_df,'New Case/s (Suspected)','New Case/s (Probable)','New Case/s (Probable)','New Cases')\n",
    "lib_new_cases = lib_new_cases.loc[lib_new_cases['New Cases'] > 0]\n",
    "lib_new_deaths = handle_data(lib_df,'Total death/s in confirmed cases','Total death/s in probable cases','Total death/s in suspected cases','Total Deaths')\n",
    "lib_new_deaths = lib_new_deaths.loc[lib_new_deaths['Total Deaths'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forming the Liberia DataFrame\n",
    "lib_df = pd.merge(lib_new_cases, lib_new_deaths, on='Date', how='outer')\n",
    "lib_df['Country'] = 'Liberia'\n",
    "lib_df.sort_values('Date', inplace=True)\n",
    "lib_df = add_month(lib_df) # Add a 'Month' column, parsed from the 'Date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Daily average deaths per month:',calculate_avg_new_deaths(lib_df))\n",
    "print('Daily average new cases per month:',calculate_avg_new_cases(lib_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forming the Final DataFrame contaning the relevant information for the 3 different counties\n",
    "\n",
    "df_merged = pd.concat([g_df,sl_df,lib_df])\n",
    "df_merged.head()\n",
    "df_merged[df_merged['Country'] == 'Guinea']\n",
    "print('Values for Guinea')\n",
    "print('Daily average deaths per month:',calculate_avg_new_deaths(df_merged[df_merged['Country'] == 'Guinea']))\n",
    "print('Daily average new cases per month:',calculate_avg_new_cases(df_merged[df_merged['Country'] == 'Guinea']))\n",
    "print('\\nValues for Sierra Leone')\n",
    "print('Daily average deaths per month:',calculate_avg_new_deaths(df_merged[df_merged['Country'] == 'Sierra Leone']))\n",
    "print('Daily average new cases per month:',calculate_avg_new_cases(df_merged[df_merged['Country'] == 'Sierra Leone']))\n",
    "print('\\nValues for Liberia')\n",
    "print('Daily average deaths per month:',calculate_avg_new_deaths(df_merged[df_merged['Country'] == 'Liberia']))\n",
    "print('Daily average new cases per month:',calculate_avg_new_cases(df_merged[df_merged['Country'] == 'Liberia']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to concatenate all excel files into one `DataFrame`. We'll make sure we have a unique index by resetting it to a temporary 0-x numerical index. We're going to be using the variable `xl_lengths` to keep track of the size of the different tables that are concatenated, and the variable `count` to double check that we import all the excel rows and don't miss something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_data = pd.DataFrame(columns=['raw','counts'])\n",
    "nb_excels = 9\n",
    "xl_lengths = np.zeros(nb_excels, dtype=int)\n",
    "counts = 0\n",
    "\n",
    "# Concat all excel files\n",
    "for i in range(nb_excels):\n",
    "    mb_new = pd.read_excel(DATA_FOLDER+\"/microbiome/MID\"+str(i+1)+\".xls\", header=None, names=['raw','counts'])\n",
    "    mb_new.fillna('unknown', inplace=True)\n",
    "    xl_lengths[i] = np.size(mb_new.index)\n",
    "    counts += mb_new['raw'].size\n",
    "    mb_data = pd.concat([mb_data, mb_new], axis=0, join='outer')\n",
    "\n",
    "# Reset indices\n",
    "mb_data = mb_data.reset_index() # creates a new 'index' column\n",
    "mb_data = mb_data.drop('index', axis=1) # dropping this new column\n",
    "\n",
    "# We visually double-check we've imported all the information\n",
    "# by comparing the counts variable to the size of the df\n",
    "print('Nb. of data points:', counts)\n",
    "print('Data frame shape', mb_data.shape)\n",
    "if counts == mb_data.shape[0]:\n",
    "    print('Great! Looks like we have imported all the data')\n",
    "mb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the metadata and fill in the `NaN` values with `unknown`, as asked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_metadata = pd.read_excel(DATA_FOLDER+\"/microbiome/metadata.xls\")\n",
    "mb_metadata.fillna('unknown', inplace=True)\n",
    "mb_metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialise the new columns that will be filled in with the metadata information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_data = pd.concat([mb_data, pd.DataFrame(columns=mb_metadata.columns)], axis=1)\n",
    "print('Data frame shape:',mb_data.shape)\n",
    "mb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add the metadata to the corresponding slices of the overall `DataFrame` using our previous `xl_length` variable to keep track of when one imported tables end and another begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for j in range(np.size(xl_lengths)):\n",
    "    if j >= 1:\n",
    "        idx = sum(xl_lengths[0:j])\n",
    "    for i in mb_metadata.columns:\n",
    "        mb_data[i][idx:idx+xl_lengths[j]+1] = mb_metadata[i][j]\n",
    "\n",
    "print(xl_lengths)\n",
    "print('Final DataFrame index is unique', mb_data.index.is_unique)\n",
    "mb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a meaningful index using all the metadata that we imported and joined together, as well as the name of the microbe being sampled. We'll also check that the index is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_excel(DATA_FOLDER+'/titanic.xls', sheetname='titanic', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Describe the type and the value range of each attribute. \n",
    "\n",
    "# We assume that we can describe the value range of each attribute\n",
    "# only if it's a numerical type\n",
    "\n",
    "types = df.dtypes\n",
    "value_range = df._get_numeric_data().apply(lambda x: (x.min(), x.max()))\n",
    "\n",
    "types.index.name = 'Attribute'\n",
    "types.columns = 'Type'\n",
    "\n",
    "value_range.index.name = 'Attribute'\n",
    "value_range.columns = 'Range'\n",
    "\n",
    "res = pd.concat(dict(Range=value_range, Type=types), axis=1).fillna('-')\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Indicate and transform the attributes that can be Categorical.\n",
    "\n",
    "# By visual inspection we can argue that the following columns could be\n",
    "# categorical : 'pclass', 'survived', 'sex', 'sibsp', 'parch', 'embarked'\n",
    "#\n",
    "# We assumed that for an attribute to be categorical it should have \n",
    "# <= 10 distinct elements. (NaN is not considered as a distinct value)\n",
    "\n",
    "\n",
    "\n",
    "categories = pd.Series([v for v in df.columns if len(df[v].unique()) < 10 ])\n",
    "\n",
    "print('Attributes to be made Categorical:\\n\\n', categories)\n",
    "for i in categories:\n",
    "    df[i] = df[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Plot a histogram for the travel class attribute\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "hist_plot = df.pclass.value_counts().plot(kind='bar')\n",
    "hist_plot.set_title('Travel Class')\n",
    "hist_plot.set_xlabel('Class')\n",
    "hist_plot.set_ylabel('Passengers')\n",
    "np.sum(df.pclass.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Plot a histogram for the embarkation port attribute\n",
    "%matplotlib inline\n",
    "\n",
    "nb_ports = df['embarked'].describe()['unique']\n",
    "df.embarked.unique()\n",
    "\n",
    "hist_plot = df.embarked.value_counts().plot(kind='bar')\n",
    "hist_plot.set_title('Embarkation port')\n",
    "hist_plot.set_xlabel('Port')\n",
    "hist_plot.set_ylabel('Passengers')\n",
    "sum(df.embarked.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Plot a histogram for the sex attribute\n",
    "%matplotlib inline\n",
    "\n",
    "hist_plot = df.sex.value_counts().plot(kind='bar')\n",
    "hist_plot.set_title('Sex')\n",
    "hist_plot.set_xlabel('Sex')\n",
    "hist_plot.set_ylabel('Passengers')\n",
    "np.sum(df.sex.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Plot a histogram for the age attribute\n",
    "\n",
    "\n",
    "nb_bins = np.ceil(df.age.max()/10).astype('int')\n",
    "hist_plot = df.age.hist(bins=nb_bins, grid=False, xlabelsize=11, ylabelsize=11, figsize=(10, 6))\n",
    "hist_plot.set_title('Age')\n",
    "hist_plot.set_xlabel('Ages')\n",
    "hist_plot.set_ylabel('Passengers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taks 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Calculate the proportion of passengers by cabin floor. \n",
    "# Present your results in a pie chart.\n",
    "\n",
    "# We assumed that the information on the cabin floor is available \n",
    "# in the column 'cabin' where the letter indicates the floor.\n",
    "# the number that follows indicates a specific cabin on that floor.\n",
    "\n",
    "# Unfortunately, this column is also filled with NaN's values.\n",
    "# For this statistic we won't try guessing the cabin floor for \n",
    "# passenger where the data is not provided. Our analysis relies\n",
    "# only on values that are already in the dataset.\n",
    "\n",
    "tot = df.cabin.describe()['count']\n",
    "\n",
    "temp = df.cabin.dropna(axis=0).apply(lambda x: str(x)[:1])\n",
    "\n",
    "D = {}\n",
    "for v in temp:\n",
    "    if not v in D:\n",
    "        D[v] = 1\n",
    "    else:\n",
    "        D[v] += 1\n",
    "\n",
    "\n",
    "labels = list(D.keys())\n",
    "values = list(D.values())\n",
    "\n",
    "\n",
    "plt.pie(values, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: For each travel class, calculate the proportion of the\n",
    "# passengers that survived. Present your results in pie charts.\n",
    "\n",
    "# The pie chart represents only passengers that survived. Each region\n",
    "# on the chart is the proportion of the passengers in the class\n",
    "# that survived among all survivors.\n",
    "\n",
    "\n",
    "tot = df.survived.describe()['count']\n",
    "\n",
    "class_tot = (df.groupby('pclass').survived.describe())['count']\n",
    "pclass_survived = df.groupby(['pclass', 'survived']).survived.describe()\n",
    "pclass_survived = (pclass_survived[pclass_survived['top'] == 1])['freq']\n",
    "pclass_survived = pclass_survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, pclass_survived], axis=1)\n",
    "prop = (stats['freq'] / stats['count'])*100\n",
    "\n",
    "l = df.set_index('pclass').index.categories\n",
    "plt.pie(list(prop), labels=list(l))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Calculate the proportion of the passengers that survived \n",
    "# by travel class and sex. Present your results in a single histogram.\n",
    "\n",
    "class_tot = (df.groupby(['pclass', 'sex']).survived.describe())['count']\n",
    "survived = df.groupby(['pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1)\n",
    "prop = (stats['freq'] / stats['count'])*100\n",
    "\n",
    "prop.unstack(level=1).plot(kind='bar', subplots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Create 2 equally populated age categories and calculate \n",
    "# survival proportions by age category, travel class and sex. Present\n",
    "# your results in a DataFrame with unique index.\n",
    "\n",
    "# Our analysis is based only on passengers that have a valid 'age'\n",
    "# field. The field is considered valid only if the value is not a NaN.\n",
    "# For this statistic we won't try guessing the passenger age when \n",
    "# the data is not provided.\n",
    "\n",
    "# We create our 2 equally populated categories as follow:\n",
    "# 1. We order the passengers by age in ascending order\n",
    "# 2. We drop from the table passengers with invalid 'age' value\n",
    "# 3. We separate the resulting dataframe in two with the cut\n",
    "#    point being half way down the table\n",
    "\n",
    "# The stats are then computed for each age category separately before \n",
    "# concatenating both resulting tables\n",
    "\n",
    "# 1.\n",
    "df.sort_values(['age'], axis=0, inplace=True)\n",
    "# 2.\n",
    "df.age.dropna(axis=0, inplace=True)\n",
    "# 3.\n",
    "mid = int(np.floor(len(df)/2))\n",
    "cat1 = df[:mid]\n",
    "cat2 = df[mid:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "# Age Category #1\n",
    "\n",
    "class_tot = (cat1.groupby(['age', 'pclass', 'sex']).survived.describe())['count']\n",
    "survived = cat1.groupby(['age', 'pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1).fillna(0)\n",
    "stats.columns = ['total', 'survivors']\n",
    "\n",
    "s1 = stats.groupby(['pclass', 'sex']).sum()\n",
    "\n",
    "s1['age'] = 'Younger'\n",
    "s1.set_index('age', append=True, inplace=True)\n",
    "s1 = s1.reorder_levels(['age', 'pclass', 'sex'])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "# Age Category #2\n",
    "\n",
    "class_tot = (cat2.groupby(['age', 'pclass', 'sex']).survived.describe())['count']\n",
    "survived = cat2.groupby(['age', 'pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1).fillna(0)\n",
    "stats.columns = ['total', 'survivors']\n",
    "\n",
    "s2 = stats.groupby(['pclass', 'sex']).sum()\n",
    "\n",
    "s2['age'] = 'Older'\n",
    "s2.set_index('age', append=True, inplace=True)\n",
    "s2 = s2.reorder_levels(['age', 'pclass', 'sex'])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "df = pd.concat([s1, s2], axis=0)\n",
    "df['proportion'] = (df['survivors'] / df['total'])*100\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Calculate the proportion of the passengers that survived \n",
    "# by travel class and sex. Present your results in a single histogram.\n",
    "\n",
    "class_tot = (df.groupby(['pclass', 'sex']).survived.describe())['count']\n",
    "survived = df.groupby(['pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1)\n",
    "prop = (stats['freq'] / stats['count'])*100\n",
    "\n",
    "prop.unstack(level=1).plot(kind='bar', subplots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Create 2 equally populated age categories and calculate \n",
    "# survival proportions by age category, travel class and sex. Present\n",
    "# your results in a DataFrame with unique index.\n",
    "\n",
    "# Our analysis is based only on passengers that have a valid 'age'\n",
    "# field. The field is considered valid only if the value is not a NaN.\n",
    "# For this statistic we won't try guessing the passenger age when \n",
    "# the data is not provided.\n",
    "\n",
    "# We create our 2 equally populated categories as follow:\n",
    "# 1. We order the passengers by age in ascending order\n",
    "# 2. We drop from the table passengers with invalid 'age' value\n",
    "# 3. We separate the resulting dataframe in two with the cut\n",
    "#    point being half way down the table\n",
    "\n",
    "# The stats are then computed for each age category separately before \n",
    "# concatenating both resulting tables\n",
    "\n",
    "# 1.\n",
    "df.sort_values(['age'], axis=0, inplace=True)\n",
    "# 2.\n",
    "df.age.dropna(axis=0, inplace=True)\n",
    "# 3.\n",
    "mid = int(np.floor(len(df)/2))\n",
    "cat1 = df[:mid]\n",
    "cat2 = df[mid:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "# Age Category #1\n",
    "\n",
    "class_tot = (cat1.groupby(['age', 'pclass', 'sex']).survived.describe())['count']\n",
    "survived = cat1.groupby(['age', 'pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1).fillna(0)\n",
    "stats.columns = ['total', 'survivors']\n",
    "\n",
    "s1 = stats.groupby(['pclass', 'sex']).sum()\n",
    "\n",
    "s1['age'] = 'Younger'\n",
    "s1.set_index('age', append=True, inplace=True)\n",
    "s1 = s1.reorder_levels(['age', 'pclass', 'sex'])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "# Age Category #2\n",
    "\n",
    "class_tot = (cat2.groupby(['age', 'pclass', 'sex']).survived.describe())['count']\n",
    "survived = cat2.groupby(['age', 'pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1).fillna(0)\n",
    "stats.columns = ['total', 'survivors']\n",
    "\n",
    "s2 = stats.groupby(['pclass', 'sex']).sum()\n",
    "\n",
    "s2['age'] = 'Older'\n",
    "s2.set_index('age', append=True, inplace=True)\n",
    "s2 = s2.reorder_levels(['age', 'pclass', 'sex'])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "df = pd.concat([s1, s2], axis=0)\n",
    "df['proportion'] = (df['survivors'] / df['total'])*100\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
